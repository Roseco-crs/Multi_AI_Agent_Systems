{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c314b5cb",
   "metadata": {},
   "source": [
    "## Deep Research with multi agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5921c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from crewai_tools import SerperDevTool, ScrapeWebsiteTool, WebsiteSearchTool \n",
    "from IPython.display import Markdown\n",
    "import os\n",
    "\n",
    "\n",
    "def llm(provider: str=\"groq\", model: str=\"meta-llama/llama-4-maverick-17b-128e-instruct\"):\n",
    "    llm = LLM(model=f\"{provider}/{model}\")\n",
    "    return llm\n",
    "\n",
    "def deep_search(topic):\n",
    "    # 1. Agents\n",
    "    researcher_agent = Agent(\n",
    "        role = \"Senior Researcher of {topic}\",\n",
    "        goal = \"Perform a deep research on the topic {topic} and provide accurate information on it\",\n",
    "        backstory=\"You deeply research {topic} and give an accurate, concise result.\"\n",
    "        \"You base your research on the outline of the topic.\"\n",
    "        \"Your research is scientific and based one critical thinking.\"\n",
    "        \"You don't invent anything, rather you provide the result of the search.\" \\\n",
    "        \"Indeed, You check very well the source of the information to avoid fallacies.\",\n",
    "        # Tools = [WebsiteSearchTool],\n",
    "        allow_delegation= False,\n",
    "        llm = llm(),\n",
    "    )\n",
    "    writer_agent = Agent(\n",
    "        role=\"Content writer specialist\",\n",
    "        goal = \"\",\n",
    "        backstory = \"You're writing on {topic}.\"\n",
    "        \"You base your writing on the work of \"\n",
    "              \"the Senior Researcher, who provides the result of \"\n",
    "              \"relevant context about the topic. \"\n",
    "              \"You follow the main objectives and \"\n",
    "              \"direction of the outline, \"\n",
    "              \"as provide by the Senior Researcher. \"\n",
    "              \"You also provide objective and impartial insights \"\n",
    "              \"and back them up with information \"\n",
    "              \"provide by the Senior Researcher. \"\n",
    "              \"You acknowledge in your opinion piece \"\n",
    "              \"when your statements are opinions \"\n",
    "              \"as opposed to objective statements.\",\n",
    "        # Tools = [WebsiteSearchTool],\n",
    "        allow_delegation = False,\n",
    "        llm = llm(\"groq\", \"moonshotai/kimi-k2-instruct\"),\n",
    "        \n",
    "    )\n",
    "    editor_agent = Agent(\n",
    "        role=\"Editor specialist\",\n",
    "        goal = \"Edite a given blog post to align with the writing \"\n",
    "        \"style of the field or the organization.\",\n",
    "        backstory=\"You are an editor who receives a blog post \"\n",
    "              \"from the Content Writer. \"\n",
    "              \"Your goal is to review the blog post \"\n",
    "              \"to ensure that it follows either scientific research best practices\" \\\n",
    "              \"or journalistic best practices, that\"\n",
    "              \"provides balanced viewpoints \"\n",
    "              \"when providing opinions or assertions, \"\n",
    "              \"and also avoids major controversial topics \"\n",
    "              \"or opinions when possible.\",\n",
    "        allow_delegation=False,\n",
    "        llm = LLM(model=\"groq/moonshotai/kimi-k2-instruct\"),\n",
    "    )\n",
    "\n",
    "    # 2. Tasks\n",
    "    researcher_task= Task(\n",
    "        description= (\n",
    "        \"1. Prioritize the latest trends, key players, and noteworthy news on {topic}.\\n\"\n",
    "        \"2. Identify the target audience, considering their interests and pain points.\\n\"\n",
    "        \"3. Develop a detailed content outline including an introduction, key points,\"\n",
    "            \"and a call to action. \\n\"\n",
    "        \"4. Include SEO keywords and relevant data or sources.\"\n",
    "    ),\n",
    "    expected_output=\"A comprehensive content plan document \"\n",
    "                    \"with an outline, audience analysis \"\n",
    "                    \"SEO keywords, and resources\",\n",
    "        agent = researcher_agent,\n",
    "        # tools= [],\n",
    "    )\n",
    "    writer_task= Task(\n",
    "        description=(\n",
    "        \"1. Use the research result to craft a compelling \"\n",
    "            \"blog post on {topic}.\\n\"\n",
    "        \"2. Incorporate SEO keywords naturally.\\n\"\n",
    "\t\t\"3. Sections/Subtitles are properly named \"\n",
    "            \"in an engaging manner.\\n\"\n",
    "        \"4. Ensure the post is structured with an \"\n",
    "            \"engaging introduction, insightful body, \"\n",
    "            \"and a summarizing conclusion.\\n\"\n",
    "        \"5. Proofread for grammatical errors and \"\n",
    "            \"alignment with the brand's voice.\\n\"\n",
    "        ),\n",
    "        expected_output=\"A well-written blog post \"\n",
    "        \"in markdown format, ready for publication, \"\n",
    "        \"each section should have 2 or 3 paragraphs.\",\n",
    "        # tools= [],\n",
    "        agent = writer_agent,\n",
    "    )\n",
    "    editor_task = Task(\n",
    "        description=(\"Proofread the given blog post for \"\n",
    "                 \"grammatical errors and \"\n",
    "                 \"alignment with the brand's voice.\"),\n",
    "        expected_output=\"A well-written blog post in markdown format, \"\n",
    "                    \"ready for publication, \"\n",
    "                    \"each section should have 2 or 3 paragraphs.\",\n",
    "        # Tools=[],\n",
    "        agent= editor_agent,\n",
    "    )\n",
    "\n",
    "    # 3. Crew\n",
    "    crew = Crew(\n",
    "        agents= [researcher_agent, writer_agent, editor_agent],\n",
    "        tasks=[researcher_task, writer_task, editor_task],\n",
    "        process = Process.sequential,\n",
    "        memory = True,\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff(inputs= {\"topic\": topic})\n",
    "    # return display(Markdown(result.raw))\n",
    "    # return Markdown(result)\n",
    "    return result.raw     # work with gr.Textbox() and gr.Markdown()\n",
    "    # return result\n",
    "\n",
    "\n",
    "# if __name__==\"__main__\":\n",
    "#     deep_search(\"AGI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2666dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7887\n",
      "* To create a public link, set `share=True` in `launch()`.\n",
      "\n",
      "ðŸ”¨ MCP server (using SSE) running at: http://127.0.0.1:7887/gradio_api/mcp/sse\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7887/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 18:10:24,579 - 135515792266816 - rag_storage.py-rag_storage:132 - ERROR: Error during short_term search: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:10:27,619 - 135515792266816 - rag_storage.py-rag_storage:132 - ERROR: Error during entities search: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:10:35,162 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during short_term save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "/home/crs/10Academy/llm-projects/multiAgent/.venv/lib/python3.10/site-packages/httpx/_models.py:408: DeprecationWarning: Use 'content=<...>' to upload raw bytes/text content.\n",
      "  headers, stream = encode_request(\n",
      "2025-07-29 18:10:39,673 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:10:42,841 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:10:45,571 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:10:49,411 - 135515792266816 - rag_storage.py-rag_storage:132 - ERROR: Error during short_term search: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:10:52,027 - 135515792266816 - rag_storage.py-rag_storage:132 - ERROR: Error during entities search: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:00,248 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during short_term save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "/home/crs/10Academy/llm-projects/multiAgent/.venv/lib/python3.10/site-packages/httpx/_models.py:408: DeprecationWarning: Use 'content=<...>' to upload raw bytes/text content.\n",
      "  headers, stream = encode_request(\n",
      "2025-07-29 18:11:08,981 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:11,571 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:14,000 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:16,537 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:19,268 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:21,722 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:24,232 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:27,300 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:29,954 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:32,569 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:34,938 - 135515792266816 - rag_storage.py-rag_storage:132 - ERROR: Error during short_term search: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:37,369 - 135515792266816 - rag_storage.py-rag_storage:132 - ERROR: Error during entities search: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:46,508 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during short_term save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "/home/crs/10Academy/llm-projects/multiAgent/.venv/lib/python3.10/site-packages/httpx/_models.py:408: DeprecationWarning: Use 'content=<...>' to upload raw bytes/text content.\n",
      "  headers, stream = encode_request(\n",
      "2025-07-29 18:11:56,051 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:11:58,248 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:12:00,637 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:12:02,730 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:12:04,735 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n",
      "2025-07-29 18:12:06,773 - 135515792266816 - rag_storage.py-rag_storage:103 - ERROR: Error during entities save: APIStatusError.__init__() missing 2 required keyword-only arguments: 'response' and 'body'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Deep Research\")\n",
    "    with gr.Row(scale=7):\n",
    "        with gr.Column(scale=5):\n",
    "            subject = gr.Textbox(label=\"Research Subject\", lines=3)\n",
    "        with gr.Column(scale=1, min_width=1):\n",
    "            search_btn = gr.Button(\"DeepSearch\")\n",
    "    with gr.Row():\n",
    "        # result = gr.Textbox(label=\"Research Result\")\n",
    "        result = gr.Markdown()\n",
    "    \n",
    "    search_btn.click(\n",
    "        fn = deep_search,\n",
    "        inputs=[subject],\n",
    "        outputs=[result]\n",
    "    )\n",
    "    \n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6bf1961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7884\n",
      "* To create a public link, set `share=True` in `launch()`.\n",
      "\n",
      "ðŸ”¨ MCP server (using SSE) running at: http://127.0.0.1:7884/gradio_api/mcp/sse\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7884/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    result = f\"\"\" # Hello {name},\\n Welcome to the real world.\\n \n",
    "    - *AI Startup*\n",
    "    - *Trading Bots powered AI*\n",
    "    \"\"\"\n",
    "    # return display(Markdown(result))  # display in notebook as markdown\n",
    "    return result\n",
    "\n",
    "# app.gr.Interface(\n",
    "#     fn = greet,\n",
    "#     inputs= [gr.Textbox(label=\"Your name\")],\n",
    "#     outputs= [gr.Textbox()]\n",
    "# )\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    input = gr.Textbox(label= \"Your name\")\n",
    "    # output= gr.Textbox()\n",
    "    output = gr.Markdown()\n",
    "    btn = gr.Button(\"Submit\")\n",
    "\n",
    "    btn.click(fn=greet, inputs=[input], outputs=[output])\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823d76b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiagent (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
